{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminaries\n",
    "\n",
    "from __future__ import absolute_import, division, print_function  # Python 2/3 compatibility\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set (Internet Access needed)\n",
    "\n",
    "##url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('pima-indians-diabetes.data', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.7</td>\n",
       "      <td>0.198</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>74</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.433</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.393</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.586</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.177</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "226               0                     101              76               0   \n",
       "312               2                     155              74              17   \n",
       "627               0                     132              78               0   \n",
       "47                2                      71              70              27   \n",
       "705               6                      80              80              36   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "226        0  35.7              0.198   26             0  \n",
       "312       96  26.6              0.433   27             1  \n",
       "627        0  32.4              0.393   21             0  \n",
       "47         0  28.0              0.586   22             0  \n",
       "705        0  39.8              0.177   28             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.781\n",
      "roc-auc is 0.828\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABHlElEQVR4nO3deXhTZfrG8e9L2TfZEdkEBBFRURDFccFBVFDHdRTHDQVRx1FAoJRNBFkF8efM4IqooICi4KBTBBUquACyCAjIWtay7y0t3d7fH4lOqS0NbZI3y/25rlzk5Jye3HkT8uQ5OTnHWGsRERGR0FHMdQARERE5lYqziIhIiFFxFhERCTEqziIiIiFGxVlERCTEqDiLiIiEGBVniUrGmDLGmM+NMUeNMdNd54kmxpjOxpjvckwnG2Ma+vB35xpjrDGmeGATulPQYzTGvGCM+SDYuST4VJyjgDFmqzEm1fsmuMcY854xpnyuZa4yxswzxhz3FqzPjTHNci1T0Rjzf8aY7d51bfJOV8vnfo0x5lljzC/GmBRjzE5jzHRjzEWBfLw+ugeoCVS11v61qCszxrQ1xmR7x+W4MWa9MebRXMtY7zgkey9Hinq/PuR6zxiT7r2/Q8aYr4wxTb3zTnmj9+bbm7MwGGOKG2P2GWP+cEAE77ozjTHnFCWjtba8tXZLUdZRkGgo7BJZVJyjx23W2vJAC+BSoN9vM4wxbYC5wH+Ac4AGwErg+986GmNMSeAb4ELgZqAicBVwEGidz32+CnQHngWqAE2Az4BbzjR8AN5U6wMbrLWZfsyS5B3jikBP4G1jzPm5lrnEW4zKW2srnel9F9JL3lx1gH3Ae6dZ9gjQIcd0R+Bw7oWMMeWAu4GjwAP+Chrp9OFAfKXiHGWstXuAOXiK9G9eAiZZa1+11h631h6y1g4EFgEveJd5GKgH3GmtXWutzbbW7rPWvmitjc99P8aYxsDTwP3W2nnW2pPW2hPW2g+ttaO8yyQYY7rm+JvcmzutMeZpY8xGYKMx5g1jzNhc9/MfY8xz3uvnGGM+NcbsN8YkGmOezWsMjDFDgOeB+7wdZRdjTDFjzEBjzDZvpzjJGHOWd/nfuq4uxpjtwLwCxth6x+QQcPHpls0nny9ZHvFuwThgjBngy3qttSeAKUDz0yw2Gc9z/ZuHgUl5LHc3nkI+FHikgMdT1RgzyxhzzBizBGiUa741xpznvX6LMWaFd9kdxpgX8ljlY8aYJGPMbmNMrxzrKWaMiTPGbDbGHDTGfGyMqeKdvcD77xHvc97G+zePGWPWGWMOG2PmGGPqe283xphXvON/1BizyhiT57h5X8cjjTFLvMv+57f7zeu1c7rnt6DHmMd9X2mM+cEYc8QYs9IY0zZXrmHe+cnGszWsqjHmQ+/4/mSMOTe/dYtj1lpdIvwCbAVu8F6vA6wGXvVOlwWygOvz+LtHgd3e69OA98/gPp8EthWwTALQNcd0Z+C7HNMW+ApP110GuBbYARjv/MpAKp5uvxiwDE/RLQk0BLYAN+Vz3y8AH+SYfgzY5P278sAMYLJ33rneLJOAckCZPNbXFtjpvV4M+AuQDVya6/Gc58PY+ZLlbe+YXAKcBC7IZ13vAcO818vjKc4L8xkDi6dw7wUqeS97vbfZXOv9Bs+HuppAJnDZaR7PNOBj79g1B3bl8Tyfl2McL/KO4cXe+78j12Of6l3XRcB+/vfa7oHnA2UdoBTwJjA1198Wz3G/d3jH+QKgODAQ+ME77yY8r6dKgPEuU+s0r+Nd3sdWDvj0t3HN67Xj4/Ob32N8Ice6a+PZctXRO17tvdPVc+TahOfD0FnAWmADcIP38U4C3nX9/qRLPv9vXAfQJQhPsqc4JwPHvf/xvwEqeefV8d7WNI+/uxnI8F7/Chh1Bvc5AFhUwDIJFFyc/5xj2gDbgWu9048D87zXrwC251p/v/zefPhjYfoG+HuO6fOBDO+b2G9vmA1P81ja4inGR/AUyyygR65lLHDMu8wR4J/5rMuXLHVyzF8CdMpnXe8Bad772wPMAhrlMwYWOA+YADyB5wPW297bbI7l6nkfawvv9By8H/byuP8Yb/amOW4bkcfznOeHFuD/gFe813977DnX9RLwjvf6OqBdjnm18hi3nMV5NtAlx3Qx4ASerzz+jKeQXQkU8+F1PCrHdDMg3fvY//Da8fH5ze8x/v6cAX3xFvUcy84BHsmRa0COeS8Ds3NM3wb87Ov/aV2Ce9Fm7ehxh7W2Ap4i0hT4bSeuw3jeaGvl8Te1gAPe6wfzWSY/Z7p8fnb8dsV63lGmAfd7b/ob8KH3en3gHO/mvSPGs7NVfzydnS/OAbblmN6G580y59/v4PSSrOd75IrAP/G8wed2mbW2kveS52Z3H7PsyXH9BJ4OLD9jvfd3trX2L9bazQU8jkl4Nmfnt0n7IWCdtfZn7/SHwN+MMSXyWLa6N3vOsduWx3IAGGOuMMbM9341cRTPB4TcOxzmXtdvO6TVB2bmeP7X4fmQlN9roD7wao7lD+H5AFjbWjsP+DcwHthrjHnLGFMxv9x5ZCqRK3fO+Wf6Wsv5GHPn/2uu1/zVnPr/bm+O66l5TJ/udSMOqThHGWvtt3i6qbHe6RTgRyCvPZbvxfMpH+Br4Cbj2RHIF98AdYwxrU6zTAqezeq/OTuvyLmmpwL3eL8bvALPJkTwvJkl5ih8lay1Fay1HX3Mm4Tnze439fBsrs35ZubTKdystSfxdDUXGWPu8PH+zzRLIC3E8wZfE/guj/kPAw2NZ8//PcA4PIWoQx7L7seTvW6O2+qd5r6n4Onu61przwLewFMwc8q9riTv9R1Ah1yvgdLW2l3k/dztAJ7ItXwZa+0PANbaf1prW+LZCbIJ0Oc0uXNnyuB/H2zJdf++PL/5Pcbc+Sfnyl/OevfpkPCm4hyd/g9ob4xp4Z2OAx4xnp89VTDGVDbGDAPaAEO8y0zG82bwqTGmqXenlqrGmP7GmD8UQGvtRuA1YKrx/MyopDGmtDGmkzEmzrvYz8Bdxpiy3h2CuhQU3Fq7As8b/gRgjrX2iHfWEuCYMaav8fyGOcYY09wYc7mPYzIV6GmMaWA8PzMbAXxkC7E3tzdnOp7NiM8X4s/9muVMebdQ3Ab8xXv9d94dqRrh2UO/hffSHE9RfSSPdWXh+U71Be/z3Cyv5XKoAByy1qYZY1rj2TqS2yDvui7Es1/ER97b3wCG59ipq7ox5nbvvP14thDl/D31G0A/73owxpxljPmr9/rl3i6+BJ4PkWl4uvD8PGiMaWaMKYtnJ7lPvI89L748v/k9xpw+AG4zxtzkfb2X9v5fq3OanBImVJyjkLV2P57NlYO809/h2QHmLmA3ns1olwJXe4vsb93gDcCveL5/PoanIFYDFudzV8/yv02DR4DNwJ3A5975r+D5bm4v8D7/20RdkKneLFNyPKYsPAWlBZCIp2uZgGdHGF9MxPMBZIH379OAZ3z829Ots54x5rZC/J2/s5wRa+0aa+2aPGY9AvzHWrvaWrvntwuen83dav63d3RO/8Cz+XQPnq02757mrv8ODDXGHMfzwebjPJb5Fs+OTt/g2WQ/13v7q3i67rnev1+EZ+sK1rOn+nA8Pw88Yoy50lo7ExgNTDPGHAN+4X/df0U837cfxvP/4SDerU35mOx9bHuA0nhe+/nx5fnN7zH+zlq7A7gdz9c3+/F8eO6D3tcjgsn1wVhERM6AMSYBz05aE1xnkcihT1giIiIhRsVZREQkxGiztoiISIhR5ywiIhJiVJxFRERCTIFnSDHGTARuBfZZa/9w4HdjjMHzE4aOeI5U1Nlau7yg9VarVs2ee+65p9yWkpJCuXK+HuNCzoTGNrA0voGjsQ0sjW/g5DW2y5YtO2CtrV7Q3/py+rL38PxWNa/D+IHnd4GNvZcrgNe9/57Wueeey9KlS0+5LSEhgbZt2/oQSc6UxjawNL6Bo7ENLI1v4OQ1tsaYfA9fm1OBm7WttQvwHHM2P7fjOd2gtdYuAioZY/xxTGUREZGo5I8Tf9fm1IO07/TettsP6xYRET949dVX2bJlyx9u37lzJzNnznSQKPIlJSUVequEP4pz7oPSQz4nCDDGdAO6AdSsWZOEhIRT5icnJ//hNvEPjW1gaXwDR2NbdCdPnqRHjx6ULFmSkiVLnjLPWotn1yHxp/T0dEqVKlXo164/ivNOTj2DSh3yPoMK1tq3gLcAWrVqZXN/otB3H4GjsQ0sjW/gaGyL7sSJEwC8+OKLxMbGnjJP4+t/v/76K9Za9u7dW+ix9cdPqWYBDxuPK4Gj1lpt0hYRkagzZswY9uzZwwUXXFCk9fjyU6qpQFugmjFmJzAYz4nEsda+AcTj+RnVJjw/pXq0SIlERETCjLWWb775hq5du1K5cuUir6/A4mytvb+A+RZ4ushJREREwtSrr75KmzZt/FKYwT/fOYuISBF8++23bNq0KWDrP3nyZMDWHe2ys7OZPHkyzzzzDDExMX5br4qziIgj1lqGDBnCkCFDgnJ/Z599dlDuJ5pMmjSJSy+91K+FGVScRUScSE9Pp2vXrkyePJnOnTszZMiQgP6kqXjx4tSqpeND+UtmZiYvv/wysbGxAXneVJxFRILsyJEj3HXXXcyfP5+hQ4cycOBA/dY4zHz55ZfccccdAXveVJxFRIJo69at3HLLLWzcuJHJkyfz4IMPuo4kZyA9PZ0BAwYwbNgwSpUqFbD7UXEWEQmSpUuXcuutt3Ly5Enmzp2rg3+EmfT0dJYvX87TTz8d0MIMKs4iIoV26NAhNm/e7NOy69ev54knnqBGjRrMnz+/yAepkOBKTU0lNjaWIUOGUKVKlYDfn4qziMgZSk9P55///CdDhw7l+PHjPv9dq1at+Pzzz7XXdJhJSUlh8+bN9OvXLyiFGVScRUR8Zq0lPj6enj17snHjRjp27Ei3bt0oXrzgt9LixYtz7bXXUqZMmSAkFX85fvw4cXFxDB48mBo1agTtflWcRUR8sG7dOp577jm+/PJLmjRpwn//+186duzoOpYE0JEjR9i6dStDhgyhWrVqQb1vf5z4QkQkYh05coSePXty8cUX88MPPzBu3DhWr16twhzhUlJS6N+/P/Xq1Qt6YQZ1ziIiecrKymLChAkMHDiQgwcP0rVrV4YNGxbUTZvixoEDB1i/fj1jx46lbNmyTjKoOIuI32RmZpKZmenXdaanp5OWlubXdRZk8eLFdO/enZUrV3LNNdfw6quvcumllwY1g7iRlZXFsGHDePHFF50VZlBxFhE/WbJkCTfeeCNHjx51HcUv6taty7Rp07j33nt19K4okZSUxOLFi3nllVecP+cqziJSZNnZ2TzzzDOULVuWuLg4v657y5YtNGzY0K/rLEjlypV56KGHnHZOEnzvvvsuzz33nPPCDCrOIuIHH374IUuWLOH999/n4Ycf9uu6ExISdCQtCaitW7cyd+5cBgwY4DrK77S3togUSXJyMn379qV169Y6TrSEHWst8+bNo3Pnzq6jnEKds4gUyahRo9i9ezeffvopxYrp876Ej19//ZUZM2bQv39/11H+QP+TRKTQEhMTGTt2LA888ABt2rRxHUfEZykpKSQmJhIbG+s6Sp7UOYuIT9LT0xk/fjwTJkwgIyMDgMOHDxMTE8OoUaMcpxPx3cqVK5k+fTrDhg1zHSVfKs4iUqDZs2fTs2dP1q9fzzXXXEOdOnV+n9epU6dTpkVC2datW7HWMnToUNdRTkvFWUTytWHDBnr27El8fLyOJy1hb8mSJcTHxzN48OCQ+LnU6eg7ZxH5g6NHj9K7d28uvPBCvvvuO8aOHavjSUtY++mnnzj77LPDojCDirOI5PDb8aQbN27MuHHj6Ny5Mxs2bKBXr16ULFnSdTyRQlm6dCnz5s2jbt26YVGYQZu1RcTru+++o3v37ixfvpw//elPzJ49m5YtW7qOJVIkX3/9Nc2aNaNv376uo5wRdc4iUS47O5tHH32Ua665hn379jF16lQWLlyowixhb/369axdu5ZzzjnHdZQzpuIsEuUmTZrEe++9R69evfj111/p1KlT2Gz6E8nPf/7zH4wxPPvss66jFIqKs0gUO378OP369ePKK6/kpZdeoly5cq4jiRTZvn372L9/P02aNHEdpdD0nbNIFBsxYgR79uzhP//5jw69KRFh2rRpnHvuuXTt2tV1lCLR/0aRKLVlyxbGjRvHQw89ROvWrV3HESmy48ePExMTw5VXXuk6SpGpcxaJUn369KFEiRKMHDnSdRSRIps4cSK1a9fmr3/9q+sofqHiLOLAhg0b+Oijj7DWOrn/o0ePMmPGDIYNG0bt2rWdZBDxlwMHDtCgQQOuv/5611H8RsVZxIFXX32V1157zWmGli1b8txzzznNIFJU48eP59xzz+WWW25xHcWvVJxFHMjKyqJGjRrs3r3bWQZjjH4yJWHtl19+4YYbbuD88893HcXvVJxFHDHGaA9pkUJ65ZVXuOiii7jhhhtcRwkIFWcREQkb1lrmzp3LY489xllnneU6TsDoY7uIiISN1157jfLly0d0YQZ1ziIiEgastbz77rs89dRTUfF1UOQ/QpEQs2rVKr744guqVKniOopI2Jg6dSotWrSIisIMKs4iQTVnzhyuvvpqAKZMmeI4jUjoy8rKYuTIkdx3331cdtllruMEjYqzSJC888473HLLLTRo0IBFixbRokUL15FEQpq1lm+++Ybbb7+dmJgY13GCSsVZJMCstQwcOJCuXbtyww03sHDhQurUqeM6lkhIy8jIIDY2lj/96U80a9bMdZyg0w5hIgF08uRJHnvsMaZMmULXrl157bXXKFGihOtYIiEtPT2d1atX8+STT0btaUzVOYsEyKFDh2jfvj1Tpkxh5MiRvPXWWyrMIgVIS0ujd+/e1K1bl0aNGrmO44w6Z5EA2LJlCx07diQxMZGpU6fSqVMn15FEQt6JEyfYvHkzsbGx1KhRw3Ucp9Q5i/jZ4sWLufLKK9m/fz9ff/21CrOID1JSUoiNjaV69eraJwMVZxG/mjlzJm3btqVChQr88MMPXHPNNa4jiYS8Y8eOsXHjRgYPHszZZ5/tOk5IUHEW8QNrLa+88gp33303LVq0YNGiRRF5phwRf0tLS6Nfv37UrVuX6tWru44TMvSds0gRZWVl8a9//YuZM2dy11138cEHH1CmTBnXsURC3qFDh1i9ejVjx47V/5lc1DmLFEFKSgp33nknM2fOpFevXkyfPl1vMiI+yM7OZvjw4bRo0UL/Z/KgzlmkCDp37sx///tfnn32WcaOHes6jkhY2LNnDwsWLGDs2LEYY1zHCUnqnEWKYN26dfzlL3/hzjvvdB1FJGy8//773HLLLSrMp6HOWaSIou2YvyKFtX37dmbNmkXfvn1dRwl56pxFRCTgsrOzmT9/Po8//rjrKGFBnbOIiATUxo0bmTJlCoMHD3YdJWyocxYRkYA5fvw4W7duZcCAAa6jhBV1ziKnkZ2dzbPPPsuyZcvynL9582aaNm0a5FQi4eGXX37hgw8+YOTIkdr56wypOIucxgcffMD48eO56qqrKF++/B/mX3vttdx///0OkomEti1btpCdnc2IESNUmAtBxVkkH8nJycTFxXH55ZezcOFCihXL/1ughISE4AUTCXHLli3js88+Y8iQIaf9fyP5U3EWyceoUaPYvXs3n376qd5gRHy0dOlSqlevztChQ9UxF4HecUTykJiYyNixY3nggQdo06aN6zgiYWHlypXMmTOHevXqqTAXkYqzSB5iY2OJiYlh1KhRrqOIhIX58+dTqVIl+vfvr8LsB9qsLVHpp59+4p133sFa+4d5aWlpfPLJJwwdOlQnfRfxQWJiIitWrOD66693HSViqDhL1ElOTuaOO+7gyJEjVKxYMc9l2rVrR+/evYOcTCT8/Pe//6VevXo899xzrqNEFBVniTqjR48mKSmJ77//nquuusp1HJGwdfjwYXbu3Mktt9ziOkrEUXGWqLJ161bGjh3L3/72NxVmkSKYPn06NWrU4IknnnAdJSJphzCJKrGxsRhjtKOXSBGcOHECgOuuu85xksilzlmixoIFC5g+fTovvPACdevWdR1HJCxNmjSJypUr89e//tV1lIim4ixRISsrix49elC3bl369OnjOo5IWNq/fz/169dXxxwEKs4SFRYsWMCKFSuYNGkSZcuWdR1HJOy8+eabnH322dx+++2uo0QFFWeJCvHx8ZQsWZI777zTdRSRsLNq1SratWvHeeed5zpK1NAOYRIV4uPjufbaa/M8s5SI5O/f//43u3fvVmEOMnXOEvG2bdvG2rVr6dq1q+soImHDWsvs2bN55JFHqFChgus4UUeds0S82bNnA9CxY0fHSUTCx4QJE6hQoYIKsyPqnCXixcfH06BBA5o0aeI6ikjIs9YyYcIEunTpolOlOqSRl4iWlpbGN998Q8eOHXWmHBEfzJgxgxYtWqgwO6bOWSLawoULOXHihDZpixQgOzubESNG0LdvX0qUKOE6TtTz6aORMeZmY8x6Y8wmY0xcHvPPMsZ8boxZaYxZY4x51P9RRc5cfHw8pUqVom3btq6jiIQsay0LFizg9ttvV2EOEQUWZ2NMDDAe6AA0A+43xjTLtdjTwFpr7SVAW+BlY0xJP2cVOWPx8fFcf/31OvCISD6ysrKIjY3l0ksv5aKLLnIdR7x86ZxbA5ustVustenANCD3IWIsUMF4vtQrDxwCMv2aVOQMbd68mQ0bNmiTtkg+0tPTSUxMpFu3bpx11lmu40gOvnznXBvYkWN6J3BFrmX+DcwCkoAKwH3W2uzcKzLGdAO6AdSsWZOEhIRT5icnJ//hNvGPSB3brKwsUlNT85wXHx8PQJUqVQL+2CN1fEOBxjYw0tPTefPNN/nLX/7Crl272LVrl+tIEacor11jrT39Asb8FbjJWtvVO/0Q0Npa+0yOZe4B/gQ8BzQCvgIusdYey2+9rVq1skuXLj3ltoSEBH03GCCROLYZGRlcc801LF68ON9lGjduzIYNGwKeJRLHN1RobP0vLS2NTZs2UbFiRbZs2aLxDZC8XrvGmGXW2lYF/a0vnfNOIOf59erg6ZBzehQYZT2VfpMxJhFoCizxYf0ihfLaa6+xePFi+vTpQ61atfJc5pprrglyKpHQduLECfr27UtcXBy1a9dmy5YtriNJHnwpzj8BjY0xDYBdQCfgb7mW2Q60AxYaY2oC5wN6xiVgDhw4wAsvvED79u0ZPXq0fsMs4oPk5GQ2bNjA888/T/Xq1V3HkdMocIcwa20m8A9gDrAO+Nhau8YY86Qx5knvYi8CVxljVgPfAH2ttQcCFVrk+eef5/jx47zyyisqzCI+yMjIIDY2ljp16qgwhwGfDkJirY0H4nPd9kaO60nAjf6NJpK3VatW8eabb/L3v/+dCy+80HUckZB3+PBhli5dyiuvvEKpUqVcxxEf6PhsElastfTs2ZNKlSoxZMgQ13FEQp61lpEjR3L55ZerMIcRHb5TwsrXX3/NvHnz+Ne//kWVKlVcxxEJafv27eOrr77SfhlhSJ2zhJXNmzcDcPfddztOIhL6Jk+ezO23367CHIbUOUtY0puNSP527drFxx9/TK9evVxHkUJS5ywiEkGys7P59ttveeqpp1xHkSJQ5ywiEiG2bNnCxIkTGTZsmOsoUkTqnEVEIsDRo0fZtm0bgwcPdh1F/EDFWcLK8ePHXUcQCTnr1q1j2LBhtG3bVudjjhAqzhI2pkyZwsCBA2nevDnVqlVzHUckJGzevJmsrCxGjRqlHSUjiIqzhDxrLcOHD+eBBx6gTZs2LFiwgOLFtbuEyKpVq3jnnXdo1qwZMTExruOIH6k4S0jLyMiga9euDBw4kAcffJA5c+ZQuXJl17FEnFu2bBkVKlRg2LBhFCumt/JIo2dUQtbRo0e55ZZbmDhxIoMGDWLSpEk6/KAIsHbtWuLj4zn33HNVmCOUtg1KSNqxYwe33HIL69atY+LEiTz66KOuI4mEhAULFnDOOecwcOBAfcccwfSRS0LOhg0buOKKK9i2bRuzZ89WYRbxSkpKYvHixTRq1EiFOcKpc5aQM2nSJPbs2cPKlSu56KKLXMcRCQlz5syhWrVq9OnTx3UUCQJ1zhJysrOzKV68uAqziFdycjKJiYm0bNnSdRQJEnXOIiIhbObMmZQvX54nn3zSdRQJInXOIiIhKjU1laysLNq3b+86igSZOmcRkRD04YcfUqZMGe655x7XUcQBFWdxIikpiQULFuQ5b+3atUFOIxJa9u7dS/369bn66qtdRxFHVJzFiaeeeopZs2blO//ss88OYhqR0DFhwgQqVaqkjjnKqThL0KWlpfHVV1/xyCOPEBcXl+cyNWvWDHIqEfdWrFhBu3btaNCggeso4piKswTdggULSE1N5d5776Vp06au44iEhDfffJM6depw6aWXuo4iIUDFWYIuPj6e0qVL07ZtW9dRRELCrFmzePDBBylXrpzrKBIi9FMqCbr4+Hiuv/56ypYt6zqKiHPvvfce5cuXV2GWU6hzlqDatGkTGzdu5Nlnn3UdRcQpay1vvfUWXbt21bmY5Q/UOUtQzZ49G4AOHTo4TiLi1hdffMHFF1+swix5UucsQRUfH0+TJk1o1KiR6ygiTmRnZzNixAh69+5N6dKlXceREKXOWYLmxIkTzJ8/n44dO7qOIuKEtZZFixZx6623qjDLaak4S9AkJCRw8uRJbdKWqJSZmUnfvn1p0qQJLVq0cB1HQpw2a0vQxMfHU7ZsWa699lrXUUSCKiMjg19//ZXHHnuMatWquY4jYUCdswSFtZb4+HjatWunzXkSVdLT04mNjeWss87SQXfEZyrO8gfvvPMOJUuWpHjx4n69JCYmapO2RJWTJ0+yceNGunfvTr169VzHkTCizdryB+vWrcNam+9xrwurdOnSPPTQQ35dp0ioSktLIzY2lt69e6swyxlTcZY8lSpVimHDhrmOIRKWUlJSWLduHYMGDaJ69equ40gY0mZtERE/ysrKIi4ujrp166owS6GpcxYR8ZOjR4/yww8/8PLLL1OyZEnXcSSMqXMWEfGTMWPGcMUVV6gwS5Gpc5Y/SE9Pdx1BJKwcOHCAL774QvtpiN+oc5ZTHD58mClTptCmTRvXUUTCxpQpU7jrrrtcx5AIos5ZTjFkyBAOHz7M2LFjXUcRCXm7d+9m8uTJxMbGuo4iEUads/xu3bp1jB8/nscff5xLLrnEdRyRkJaVlcXChQv5xz/+4TqKRCAVZ/ndc889R7ly5XjxxRddRxEJaVu3bqV///7ce++9lC1b1nUciUDarC2A56QUX375JS+//LJ+mylyGocPH2b79u36ECsBpc5ZyMzMpGfPnjRp0kSb6EROY/369QwbNow//elP+rmUBJQ6Z2H16tVs2LCB999/X284IvnYtGkTmZmZjB49mpiYGNdxJMKpcxaWL18OoJ9PieRjzZo1vPPOOzRt2pTixdXTSOCpOAsrVqygQoUKNGrUyHUUkZCzYsUKSpcuzfDhw9UxS9CoOAsrVqzgkksuoVgxvRxEctq0aROfffYZDRs21P8PCSq92qJcVlYWK1eu5NJLL3UdRSSkfP/992RkZPDCCy9gjHEdR6KMinOU27RpEykpKSrOIjns37+fhQsX0rRpUxVmcUJ7NkS5FStWAHDZZZc5TiISGr7++mvKli1LXFyc6ygSxdQ5R7kVK1ZQsmRJmjVr5jqKiHOpqals3LiRq666ynUUiXLqnKPc8uXLad68OSVKlHAdRcSpWbNmUaxYMZ566inXUUTUOUczay0rVqzQ980S9VJTU0lPT+fWW291HUUEUOcc1Xbu3MnBgwdVnCWqTZs2DYBOnTo5TiLyPyrOUey3ncFUnCVa7d69m/r16+voeBJyVJyj2IoVKzDGcPHFF7uOIhJ07777LmXKlFHHLCFJxTmKrVixgvPPP5/y5cu7jiISVEuXLqVdu3bUq1fPdRSRPGmHsCimncEkGk2cOJFdu3apMEtIU+ccpQ4ePMj27dt1/maJKp999hmdOnWibNmyrqOInJY65yilncEk2kybNo1y5cqpMEtYUOfsiLWWffv2Be3+Dh06xN69e3+f/v777wEVZ4l81lrefPNNunbtqnMxS9jQK9WR++67j+nTpzvNUL9+fapWreo0g0igzZ07l+bNm6swS1jRq9WB+Ph4pk+fTteuXYN2wokNGzbQpEmTU25r2bJlUO5bxAVrLSNGjKBHjx6UK1fOdRyRM6LiHGTp6ek899xzNGnShPHjx1OyZMmg3G9CQgJt27YNyn2JuJadnc3y5cu5+eabVZglLGmHsCAbP34869evZ9y4cUErzCLRJCsri/79+1O7dm1tHZKwpc45iPbv38+QIUO4+eab6dixo+s4IhEnMzOTjRs38tBDD1GrVi3XcUQKTZ1zEA0aNIjk5GTGjRuHMcZ1HJGIkpGRQd++fSlVqhQXXnih6zgiRaLiHCQrV67k7bff5umnn+aCCy5wHUckoqSnp7NhwwaefvppGjZs6DqOSJGpOAeBtZYePXpQuXJlXnjhBddxRCJKeno6ffr0oVy5cirMEjH0nXMQzJw5k4SEBMaPH0/lypVdxxGJGKmpqaxatYpBgwZRrVo113FE/Eadc4ClpaXRu3dvmjdvTrdu3VzHEYkY1lr69etHvXr1VJgl4qhzDrBXXnmFxMREvv76ax2hSMRPjh8/zvz58xkzZgwlSpRwHUfE79Q5B1BSUhLDhw/n9ttvp127dq7jiESMl19+mauuukqFWSKWWrkA6t+/PxkZGYwdO9Z1FJGIcOjQIT799FPtWCkRz6fO2RhzszFmvTFmkzEmLp9l2hpjfjbGrDHGfOvfmOHnp59+4v3336dHjx6cd955ruOIRISPPvqIe++913UMkYArsHM2xsQA44H2wE7gJ2PMLGvt2hzLVAJeA2621m43xtQIUN6wYK2le/fu1KxZkwEDBriOIxL29u7dy9tvv83AgQNdRxEJCl82a7cGNllrtwAYY6YBtwNrcyzzN2CGtXY7gLU2eCcqDkFTp07lxx9/5J133qFixYqu44iEtaysLL7//nt69uzpOopI0PiyWbs2sCPH9E7vbTk1ASobYxKMMcuMMQ/7K2C4SUlJITY2lssuu4zOnTu7jiMS1nbs2MGbb77JnXfeqbNLSVTxpXPO6yDQNo/1tATaAWWAH40xi6y1G05ZkTHdgG4ANWvWJCEh4ZSVJCcn/+G2cPPuu++ya9cuYmNjWbBgges4v4uEsQ1lGl//O3r0KDt37qRTp058+23U78YSMHrtBk5RxtaX4rwTqJtjug6QlMcyB6y1KUCKMWYBcAlwSnG21r4FvAXQqlUrm/v8wuF+zuEdO3bw8ccfc9999/Hss8+6jnOKcB/bUKfx9a9Nmzbx2WefMXbsWL777juNbQDptRs4RRlbXzZr/wQ0NsY0MMaUBDoBs3It8x/gGmNMcWNMWeAKYF2hEoWxBQsWkJaWRlxcnju0i4gPNm/ezMmTJxkzZowO3CNRq8DibK3NBP4BzMFTcD+21q4xxjxpjHnSu8w64EtgFbAEmGCt/SVwsUOTtZ6t/eXLl3ecRCQ8rV+/njfffJPzzz9fBxiRqObTx1JrbTwQn+u2N3JNjwHG+C+aiESTlStXUqZMGUaOHElMTIzrOCJO6fCdIuLc9u3bmT59Ouedd54Kswg6fKeIOLZ48WLKlCnDiy++iDF5/ThEJPqocxYRZ44cOcK8efO46KKLVJhFclDnLCJO/Pb7z379+rkNIhKC1DmLSNClp6fz66+/6ve1IvlQ5ywiQRUfH09aWhpPPvmk6ygiIUuds4gETWpqKidPnuSuu+5yHUUkpKlzFpGg+OSTT0hNTeWhhx5yHUUk5Kk4i0jA7dy5k3r16tG6dWvXUUTCgoqziATUBx98gDGGBx54wHUUkbCh4iwiAbN48WKuv/56atfOfQp4ETkd7RAmIgExefJkdu3apcIsUgjqnEXE7z799FPuueceypQp4zqKSFhS5ywifjVjxgzKlSunwixSBOqcRcQvrLW8/vrrdO3alZIlS7qOIxLW1Dn7UXp6OoAO4C9R6dtvv+XCCy9UYRbxAxVnP/r++++pVKkS9evXdx1FJGistQwfPpwWLVpw3XXXuY4jEhFUnP3EWsvs2bO58cYbKV5c3xZIdLDWsmrVKtq3b0+lSpVcxxGJGCrOfrJy5Up2795Nx44dXUcRCYrs7GwGDhxI5cqVdeQvET9Ti+cn8fHxANx8882Ok4gEXlZWFlu2bOG+++6jXr16ruOIRBx1zn4SHx9Py5YtqVmzpusoIgGVmZlJXFwc1louvvhi13FEIpKKsx8cPnyYH3/8UZu0JeJlZGSwfv16nnzySZo0aeI6jkjEUnH2g7lz55Kdna3iLBEtMzOT2NhYSpcuTaNGjVzHEYlo+s7ZD+Lj46latSqXX3656ygiAZGWlsayZcsYNGgQVapUcR1HJOKpcy6i7OxsvvzyS2666SZiYmJcxxHxO2stAwYMoH79+irMIkGizrmIli9fzr59+7RJWyJScnIyc+fOZfTo0fr9vkgQqXMuovj4eIwx3HTTTa6jiPjdq6++ytVXX63CLBJk+h9XRPHx8bRu3Zpq1aq5jiLiN0eOHGHKlCkMGDDAdRSRqKTOuQgOHDjAkiVLtElbIs4nn3zC/fff7zqGSNRS51wEc+bMwVpLhw4dXEcR8Yv9+/czfvx4XnjhBddRRKKaOuciiI+Pp3r16rRs2dJ1FJEiy8jIYNGiRfTq1ct1FJGop+JcSFlZWcyZM4cOHTpQrJiGUcLbrl276NOnD7feeisVKlRwHUck6qmqFNJPP/3EwYMHtUlbwt7+/fvZtWsXI0eOxBjjOo6IoOJcaPHx8RQrVowbb7zRdRSRQktMTGTYsGG0aNGCMmXKuI4jIl7aIayQZs+eTZs2bXTEJAlbmzdv5uTJk4wZM4aSJUu6jiMiOahzLoS9e/eydOlSbdKWsLV582Zef/11mjRposIsEoLUORfCl19+CaDfN0tY+uWXX4iJiWH06NE6HrxIiFLnXAjx8fHUqlWLFi1auI4ickZ2797NlClTOP/881WYRUKYOuczlJmZydy5c7nzzju1Z6uElaVLlwIwfPhwvXZFQpyKsw/WrFnDli1bANiyZQtHjhzRJm0JKykpKcyZM4f+/furMIuEARXnAqxYsYJWrVqRnZ39+21lypThhhtucJhKxHcLFy7kxIkTOomFSBhRcT4Nay3du3enatWqzJo1ixIlSgBQo0YNKlWq5DaciA8yMzNZu3Yt3bp1cx1FRM6AivNpfPLJJyxcuJA333yTK6+80nUckTMyZ84cDh06xBNPPOE6ioicIe2tnY/U1FR69+7NJZdcQpcuXVzHETkjJ06cIC0tTad9FAlT6pzz8fLLL7N9+3bef/99/eREwspnn33GoUOHeOyxx1xHEZFCUnHOw28nAbj77rtp27at6zgiPtu2bRt169bljjvucB1FRIpAxTkPcXFxZGVlMWbMGNdRRHw2depU0tPTeeSRR1xHEZEiUnHOZdGiRXzwwQf079+fBg0auI4j4pPvv/+etm3bUqtWLddRRMQPtENYDtnZ2XTv3p1atWrRr18/13FEfDJt2jR27dqlwiwSQdQ55/Dhhx+yZMkS3n//fcqXL+86jkiBPvnkE+644w5Kly7tOoqI+JE6Z6/k5GT69u1L69atefDBB13HESnQF198QalSpVSYRSKQOmevUaNGsXv3bj799FOKFdNnFgltr7/+Op07d6ZMmTKuo4hIAKgKAYcOHWLs2LE88MADtGnTxnUckdP64YcfOP/881WYRSKYijOwf/9+Tp48qTNNSUiz1jJy5EgaN27Mn//8Z9dxRCSAVJxz0Kn0JFRZa/n111+57rrrqF69uus4IhJgKs4iIS47O5vBgwdTokQJrrrqKtdxRCQIVJxFQlh2djaJiYncddddnHfeea7jiEiQqDiLhKisrCz69evHyZMnadGihes4IhJE+imVSAjKzMxk/fr1dOvWjUaNGrmOIyJBps5ZJMRkZ2cTGxtLyZIlVZhFopQ6Z5EQcvLkSRYvXszzzz9PpUqVXMcREUfUOYuEkMGDB3PuueeqMItEOXXOIiHgxIkTfPHFFwwfPpyYmBjXcUTEMXXOIiFg/PjxXHvttSrMIgKocxZx6tixY7z77rv06dPHdRQRCSHqnEUcsdYyc+ZMnaJURP5AxVnEgYMHDzJgwAAeeeQRqlat6jqOiIQYFWeRIDt58iRLliwhLi7OdRQRCVEqziJBtHv3bnr37s2NN95IxYoVXccRkRCl4iwSJPv27WPXrl2MHj1ae2WLyGmpOIsEwbZt2xg2bBjNmzenbNmyruOISIjTT6lEAiwxMZETJ04wZswYSpUq5TqOiIQBdc4iAbRt2zb+9a9/0aRJExVmEfGZOmeRAFm3bh1ZWVm89NJLFC+u/2oi4jt1ziIBcODAAd577z0uuOACFWYROWN61xDxsxUrVpCamsqoUaMwxriOIyJhyKfO2RhzszFmvTFmkzEm3yMnGGMuN8ZkGWPu8V9EkfCRlpZGfHw8V155pQqziBRagZ2zMSYGGA+0B3YCPxljZllr1+ax3GhgTiCCioS6H3744ffDcoqIFIUvnXNrYJO1dou1Nh2YBtyex3LPAJ8C+/yYTyQsZGVl8csvv3Drrbe6jiIiEcCX4lwb2JFjeqf3tt8ZY2oDdwJv+C+aSHj45ptv+Oqrr+jWrZs2ZYuIX/iyQ1he7zY21/T/AX2ttVmne3MyxnQDugHUrFmThISEU+YnJyf/4bZg2L59OwBr1651cv/B4GpsI11qaio///wzV199tcY3QPTaDSyNb+AUZWx9Kc47gbo5pusASbmWaQVM8xbmakBHY0ymtfaznAtZa98C3gJo1aqVbdu27SkrSUhIIPdtwbB+/XoAmjVr5uT+g8HV2EayL774gqSkJPr166fxDSCNbWBpfAOnKGPrS3H+CWhsjGkA7AI6AX/LuYC1tsFv140x7wFf5C7MIpFky5Yt1KlTR98xi0hAFFicrbWZxph/4NkLOwaYaK1dY4x50jtf3zNLVJk+fTrHjh2jS5curqOISITy6SAk1tp4ID7XbXkWZWtt56LHEglNCxYs4LrrrqNGjRquo4hIBNPhO0V8NGPGDJKSklSYRSTgdPhOER9Mnz6dW2+9lTJlyriOIiJRQJ2zSAG++uorSpQoocIsIkGjzlnkNF5//XUeeughypcv7zqKiEQRdc4i+Vi2bBmNGjVSYRaRoFNxFsnFWstLL71ErVq1uPHGG13HEZEopOIskoO1ls2bN9OmTRvOOecc13FEJEqpOIt4WWsZMmQIGRkZXHPNNa7jiEgU0w5hIkB2djbbtm3jL3/5CxdccIHrOCIS5dQ5S9TLzs5mwIABHD9+nMsuu8x1HBERdc4S3bKysli7di2PP/44DRs2dB1HRARQ5yxRzFpLXFwcJUqUUGEWkZCizlmiUnp6OgsXLmTgwIGcddZZruOIiJxCnbNEpaFDh9KwYUMVZhEJSeqcJaqkpqYyY8YMhg4dSrFi+mwqIqFJ704SVd544w3atm2rwiwiIS1qOufU1FT++c9/kpyc/Id5Bw4ccJBIgun48eO89dZb9OrVy3UUEZECRU1x/vHHH4mLi8MYgzHmD/PLli2rPXYjlLWWzz//nIcffth1FBERn0RNcc7OzgZgwYIFXH311Y7TSLAcPnyYkSNHMnr06Dw/lImIhCJ98SYRKy0tjWXLltG/f38VZhEJKyrOEpH27t1Lr169uO6666hUqZLrOCIiZ0TFWSLOvn372LVrFy+99BIlSpRwHUdE5IypOEtE2blzJy+++CIXXHAB5cqVcx1HRKRQomaHMIl827ZtIzk5mTFjxlC6dGnXcURECk2ds0SEpKQk/u///o/GjRurMItI2FPnLGFvw4YNpKam6jtmEYkY6pwlrB09epQJEyZw4YUXqjCLSMRQ5yxha9WqVRw6dEgHGBGRiBNxxXn79u2kpqb+4fYdO3Y4SCOBkpGRwRdffPH7IVlFRCJJRBXn8ePH849//OO0y2hnofC3ZMkSduzYQf/+/V1HEREJiIgpzvv27WPAgAFcd911PPHEE3kuU7FiRS677LIgJxN/ys7OZtWqVXTp0sV1FBGRgImY4jxo0CBSUlJ44403aNq0qes4EgAJCQls3LiRxx9/3HUUEZGAioi9tVeuXMmECRN4+umnVZgj1LFjx0hNTaVr166uo4iIBFzYd87WWnr06EHlypUZPHiw6zgSALNnz2bz5s0F7k8gIhIpwr44z5gxg4SEBF577TUqV67sOo742caNG6lTpw4dOnRwHUVEJGjCerN2WloavXv3pnnz5voeMgJ99tlnJCQkcNFFF7mOIiISVGHdOY8bN46tW7fy9ddfU7x4WD8UySUhIYGrr76aatWquY4iIhJ0Yds5JyUlMWLECO644w7atWvnOo740eeff87OnTtVmEUkaoVtu9mvXz8yMjIYO3as6yjiRx999BG33XYbZcuWdR1FRMSZsOyclyxZwqRJk+jZsyeNGjVyHUf85Ntvv6V48eIqzCIS9cKuc7bW0r17d2rWrMmAAQNcxxE/eeONN7jvvvu0x72ICGFQnDMzM7n33nt/P3HFyZMnWb16NRMnTqRChQqO04k/rF69mnr16qkwi4h4hfxm7bVr1zJz5kwAatSoQd26denduzePPPKI42TiDy+//DLly5enY8eOrqOIiISMkO+cV6xYAcCkSZO44IILHKcRf7HWsn37dlq2bEmDBg1cxxERCSkh3zmvWLGCsmXL0qRJE9dRxE+stQwfPpwjR47Qtm1b13FEREJOWBTniy++mJiYGNdRxA+stWzbto0OHTpwySWXuI4jIhKSQro4Z2dn8/PPP+sczBEiOzubQYMGcfjwYVq2bOk6johIyArp75wTExM5duwYl156qesoUkRZWVn88ssvdOnSRd8xi4gUIKQ75992BlNxDm/WWgYMGEDx4sVVmEVEfBDSnfPy5cspXrw4zZs3dx1FCikjI4P58+czYMAA/S5dRMRHId85N2vWjFKlSrmOIoU0YsQIGjZsqMIsInIGQrpzXrFiBTfffLPrGFIIaWlpfPTRRwwaNIhixUL6M6CISMgJ2XfN3bt3s3fvXu2pHaYmTpzIn//8ZxVmEZFCCNnOWTuDhaeUlBT+/e9/07dvX9dRRETCVsi2Nb8VZx2oInxYa4mPj6dz586uo4iIhLWQLs7nnXceFStWdB1FfHDkyBF69erF3XffTc2aNV3HEREJayFbnJcvX65N2mEiNTWVlStXMnDgQH3HLCLiByH5TnrkyBESExNVnMPAgQMH6N27N1dccQVVqlRxHUdEJCKE5A5hP//8M4D21A5x+/fvZ9euXYwaNYrSpUu7jiMiEjFCsnPWntqhb/fu3QwZMoTGjRvrACMiIn4Wkp3zunXrqF69OjVq1HAdRfKwY8cOjhw5wpgxYyhTpozrOCIiESckO+fMzExtJg1R+/btY+zYsTRu3FiFWUQkQEKyc5bQtGnTJo4ePcqYMWMoWbKk6zgiIhErJDtnCT0pKSm89dZbXHzxxSrMIiIBps5ZCrRmzRp27drF6NGjMca4jiMiEvHUOctpZWVlMWvWLNq1a6fCLCISJOqcJV/Lli1j/fr19OvXz3UUEZGoos5Z8pSVlcXq1au5//77XUcREYk66pzlD7777jtWrVrF3//+d9dRRESikjpnOcXRo0c5ceIETz31lOsoIiJRS52z/O6rr75izZo19OjRw3UUEZGopuIsAPz666/Url2b9u3bu44iIhL1tFlb+OKLL5g/fz7NmjVzHUVERFDnHPXmz59PmzZtuPXWW11HERERL3XOUezLL79k27ZtVK1a1XUUERHJQZ1zlPr444/p2LEj5cuXdx1FRERyUecchRYtWgSgwiwiEqJ8Ks7GmJuNMeuNMZuMMXF5zH/AGLPKe/nBGHOJ/6OKP7z99ts0bNiQe++913UUERHJR4GbtY0xMcB4oD2wE/jJGDPLWrs2x2KJwHXW2sPGmA7AW8AVvoZITU2lS5cubNq0iSpVqrB69WpiYmLO7JFIgTZs2MDZZ59NjRo1XEcREZHT8KVzbg1sstZusdamA9OA23MuYK39wVp72Du5CKhzJiE2b97M1KlTSUpK4siRI9StW5cHHnjgTFYhBfjkk0+w1nLbbbe5jiIiIgXwZYew2sCOHNM7OX1X3AWYndcMY0w3oBtAzZo1SUhIACAxMRGAhx56iJtuuun35X+bL4VnreXgwYPUqlWL3bt3s3v3bteRIlJycrJerwGisQ0sjW/gFGVsfSnOeZ3E1+a5oDHX4ynOV+c131r7Fp5N3rRq1cq2bdsWgGrVqgFQunRpfrtNis5ay6hRo2jfvj3VqlXT2AZQQkKCxjdANLaBpfENnKKMrS+btXcCdXNM1wGSci9kjLkYmADcbq09WKg04jfWWrZv30779u1p1aqV6zgiInIGfCnOPwGNjTENjDElgU7ArJwLGGPqATOAh6y1G/wfU86EtZbBgwezb98+FWYRkTBU4GZta22mMeYfwBwgBphorV1jjHnSO/8N4HmgKvCaMQYg01qrquBAdnY2K1eupEuXLtSvX991HBERKQSfjhBmrY0H4nPd9kaO612Brv6NJoUxePBg7r33XhVmEZEwpsN3RojMzEzmzp1LXFwc5cqVcx1HRESKQIfvjBAvvfQS5513ngqziEgEUOcc5k6ePMnkyZPp168f3u/7RUQkzKlzDnPvv/8+7du3V2EWEYkg6pzD1IkTJxg3bhwDBgxQYRYRiTDqnMOQtZa5c+fSpUsXFWYRkQik4hxmjh07Rs+ePbntttuoVauW6zgiIhIAKs5hJCUlhdWrVzNw4ECdUlNEJIKpOIeJQ4cO0adPH1q0aPH7iUJERCQyaYewMHDgwAF27drFyJEj9TtmEZEooM45xO3du5cXXniBhg0bctZZZ7mOIyIiQaDOOYTt2rWLgwcPMnr0aHXMIiJRRJ1ziDp06BCjRo2icePGKswiIlFGnXMISkxMZO/evYwbN44SJUq4jiMiIkGmzjnEnDx5ktdff53LLrtMhVlEJEqpcw4hv/76K5s2beKll15yHUVERBxS5xwirLXMmjWLDh06uI4iIiKOqXMOAT///DM///wzsbGxrqOIiEgIUOfsWFZWFqtXr+bhhx92HUVEREKEOmeHFi1axKJFi+jRo4frKCIiEkLUOTty+PBhUlJS6N69u+soIiISYtQ5OzBv3jyWL19O7969XUcREZEQpOIcZGvWrKF27dr8+c9/dh1FRERClDZrB9GcOXOYN28e559/vusoIiISwtQ5B8m8efNo1aoVN910k+soIiIS4tQ5B8G8efNITEykatWqrqOIiEgYUOccYNOnT6d9+/b6jllERHymzjmAli9fTkZGBpUqVXIdRUREwoiKc4C888471KhRg7/97W+uo4iISJhRcQ6ArVu3UqVKFerUqeM6ioiIhCEVZz/717/+xbFjx7jzzjtdRxERkTCl4uxHe/fupWnTplx88cWuo4iISBhTcfYDay2jR49my5YttG/f3nUcEREJc/opVRFZa9m+fTs33HADLVu2dB1HREQigDrnIrDWMnToUJKSklSYRUTEb9Q5F1J2djbLly/nscceo27duq7jiIhIBFHnXEhDhw4lJiZGhVlERPxOnfMZysrK4r///S99+/alTJkyruOIiEgEUud8hsaNG0fjxo1VmEVEJGDUOfsoIyODiRMn0rt3b4wxruOIiEgEU+fsow8//JD27durMIuISMCpcy5AWloao0aNYvDgwSrMIiISFOqcTyM7O5t58+bx+OOPqzCLiEjQqDjnIzk5mZ49e3LDDTdQu3Zt13FERCSKqDjnISUlhbVr1zJw4EBKlizpOo6IiEQZFedcDh8+TJ8+fWjatCnVq1d3HUdERKKQdgjL4eDBg+zcuZMRI0ZQsWJF13FERCRKqXP2OnDgAM8//zwNGjSgUqVKruOIiEgUU+cM7Nmzhz179jB69GjKly/vOo6IiES5qO+cjx07xvDhw2nSpIkKs4iIhISo7py3bdvG9u3bGTduHCVKlHAdR0REBIjizjkzM5PXX3+d1q1bqzCLiEhIicrOeePGjfzyyy+MGjXKdRQREZE/iLrO2VrLrFmzuO2221xHERERyVNUdc6rV6/mxx9/pFevXq6jiIiI5CtqOufMzExWr15N165dXUcRERE5rajonH/66Sfmz59PbGys6ygiIiIFivjO+cCBA5w4cYI+ffq4jiIiIuKTiC7OCxYs4O233+a6667T+ZhFRCRsRGxxXr16NbVq1SIuLs51FBERkTMSkcX5m2++4euvv6Zx48bqmEVEJOxE3A5h33zzDZdccgnt2rVzHUVERKRQIqpz/u6779i0aRPVqlVzHUVERKTQIqZz/uSTT7j++uu5+uqrXUcREREpkojonNesWcOJEyeoWrWq6ygiIiJFFvbF+b333qNMmTI8/PDDrqOIiIj4RVgX56SkJMqXL0/Dhg1dRxEREfGbsC3Or7/+OklJSdxzzz2uo4iIiPhVWBbnAwcO0KhRI1q1auU6ioiIiN+FXXEeN24ca9eu5cYbb3QdRUREJCDC5qdU1lq2bdvGddddR8uWLV3HERERCZiw6JyttYwYMYIdO3aoMIuISMQL+c7ZWsuSJUvo3LkztWvXdh1HREQk4EK+cx4xYgQxMTEqzCIiEjVCtnPOzs7ms88+o1evXpQuXdp1HBERkaAJ2c753//+N02aNFFhFhGRqONTcTbG3GyMWW+M2WSMictjvjHG/NM7f5Ux5rLCBsrIyGD8+PE888wzNG/evLCrERERCVsFFmdjTAwwHugANAPuN8Y0y7VYB6Cx99INeL2wgaZPn85NN92EMaawqxAREQlrvnTOrYFN1tot1tp0YBpwe65lbgcmWY9FQCVjTK0zDTNv3jw6derEeeedd6Z/KiIiEjF8Kc61gR05pnd6bzvTZQrUsmVLihUL2a/BRUREgsKXvbXz2r5sC7EMxphueDZ7U7NmTRISEgA4ceIEo0aN4pxzzvn9NvGv5ORkjW0AaXwDR2MbWBrfwCnK2PpSnHcCdXNM1wGSCrEM1tq3gLcAWrVqZdu2bfv7vI4dO5KQkEDO28R/NLaBpfENHI1tYGl8A6coY+vLNuSfgMbGmAbGmJJAJ2BWrmVmAQ9799q+Ejhqrd1dqEQiIiJRrsDO2VqbaYz5BzAHiAEmWmvXGGOe9M5/A4gHOgKbgBPAo4GLLCIiEtmMtX/4ajg4d2zMfmBbrpurAQccxIkGGtvA0vgGjsY2sDS+gZPX2Na31lYv6A+dFee8GGOWWmtbuc4RiTS2gaXxDRyNbWBpfAOnKGOr3y2JiIiEGBVnERGREBNqxfkt1wEimMY2sDS+gaOxDSyNb+AUemxD6jtnERERCb3OWUREJOoFvTgH8/ST0ciH8X3AO66rjDE/GGMucZEzHBU0tjmWu9wYk2WMuSeY+cKdL+NrjGlrjPnZGLPGGPNtsDOGKx/eF84yxnxujFnpHVsdq8JHxpiJxph9xphf8plfuJpmrQ3aBc9BTDYDDYGSwEqgWa5lOgKz8Ryv+0pgcTAzhvPFx/G9Cqjsvd5B4+u/sc2x3Dw8B+a5x3XucLn4+NqtBKwF6nmna7jOHQ4XH8e2PzDae706cAgo6Tp7OFyAa4HLgF/ymV+omhbszjlop5+MUgWOr7X2B2vtYe/kIjzHQZeC+fLaBXgG+BTYF8xwEcCX8f0bMMNaux3AWqsx9o0vY2uBCsYYA5THU5wzgxszPFlrF+AZr/wUqqYFuzgH7fSTUepMx64Lnk90UrACx9YYUxu4E3gjiLkihS+v3SZAZWNMgjFmmTHm4aClC2++jO2/gQvwnLBoNdDdWpsdnHgRr1A1zZezUvmT304/KXnyeeyMMdfjKc5XBzRR5PBlbP8P6GutzfI0IHIGfBnf4kBLoB1QBvjRGLPIWrsh0OHCnC9jexPwM/BnoBHwlTFmobX2WICzRYNC1bRgF2e/nX5S8uTT2BljLgYmAB2stQeDlC3c+TK2rYBp3sJcDehojMm01n4WlIThzdf3hgPW2hQgxRizALgEUHE+PV/G9lFglPV8SbrJGJMINAWWBCdiRCtUTQv2Zm2dfjKwChxfY0w9YAbwkDqOM1Lg2FprG1hrz7XWngt8Avxdhdlnvrw3/Ae4xhhT3BhTFrgCWBfknOHIl7HdjmeLBMaYmsD5wJagpoxchappQe2crU4/GVA+ju/zQFXgNW+Hl2l10PsC+Ti2Uki+jK+1dp0x5ktgFZANTLDW5vnzFfkfH1+7LwLvGWNW49kM29daqzNV+cAYMxVoC1QzxuwEBgMloGg1TUcIExERCTE6QpiIiEiIUXEWEREJMSrOIiIiIUbFWUREJMSoOIuIiIQYFWcREZEQo+IsIiISYlScRUREQsz/AxthvZF4X1HAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 25ms/step - loss: 0.6216 - accuracy: 0.7014 - val_loss: 0.6203 - val_accuracy: 0.6979\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6192 - accuracy: 0.7049 - val_loss: 0.6180 - val_accuracy: 0.7031\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6168 - accuracy: 0.7049 - val_loss: 0.6157 - val_accuracy: 0.7031\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.7031 - val_loss: 0.6134 - val_accuracy: 0.7031\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.7101 - val_loss: 0.6112 - val_accuracy: 0.7031\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6101 - accuracy: 0.7118 - val_loss: 0.6091 - val_accuracy: 0.7031\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.7153 - val_loss: 0.6069 - val_accuracy: 0.7031\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6057 - accuracy: 0.7153 - val_loss: 0.6049 - val_accuracy: 0.7135\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6036 - accuracy: 0.7153 - val_loss: 0.6028 - val_accuracy: 0.7135\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6015 - accuracy: 0.7205 - val_loss: 0.6008 - val_accuracy: 0.7240\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.7205 - val_loss: 0.5989 - val_accuracy: 0.7240\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5974 - accuracy: 0.7205 - val_loss: 0.5969 - val_accuracy: 0.7292\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5954 - accuracy: 0.7188 - val_loss: 0.5950 - val_accuracy: 0.7344\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5935 - accuracy: 0.7188 - val_loss: 0.5932 - val_accuracy: 0.7344\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5915 - accuracy: 0.7240 - val_loss: 0.5913 - val_accuracy: 0.7344\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5896 - accuracy: 0.7240 - val_loss: 0.5895 - val_accuracy: 0.7344\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5878 - accuracy: 0.7257 - val_loss: 0.5877 - val_accuracy: 0.7344\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5859 - accuracy: 0.7292 - val_loss: 0.5860 - val_accuracy: 0.7344\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5841 - accuracy: 0.7292 - val_loss: 0.5843 - val_accuracy: 0.7292\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5823 - accuracy: 0.7292 - val_loss: 0.5826 - val_accuracy: 0.7240\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5805 - accuracy: 0.7326 - val_loss: 0.5809 - val_accuracy: 0.7240\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5788 - accuracy: 0.7361 - val_loss: 0.5793 - val_accuracy: 0.7240\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5770 - accuracy: 0.7396 - val_loss: 0.5777 - val_accuracy: 0.7240\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5753 - accuracy: 0.7431 - val_loss: 0.5761 - val_accuracy: 0.7240\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5736 - accuracy: 0.7413 - val_loss: 0.5745 - val_accuracy: 0.7240\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5720 - accuracy: 0.7448 - val_loss: 0.5730 - val_accuracy: 0.7240\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5703 - accuracy: 0.7448 - val_loss: 0.5714 - val_accuracy: 0.7292\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5687 - accuracy: 0.7448 - val_loss: 0.5699 - val_accuracy: 0.7292\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5671 - accuracy: 0.7465 - val_loss: 0.5684 - val_accuracy: 0.7292\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5656 - accuracy: 0.7448 - val_loss: 0.5670 - val_accuracy: 0.7292\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5640 - accuracy: 0.7483 - val_loss: 0.5655 - val_accuracy: 0.7292\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5625 - accuracy: 0.7465 - val_loss: 0.5641 - val_accuracy: 0.7344\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5610 - accuracy: 0.7465 - val_loss: 0.5627 - val_accuracy: 0.7344\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7448 - val_loss: 0.5614 - val_accuracy: 0.7344\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5580 - accuracy: 0.7431 - val_loss: 0.5600 - val_accuracy: 0.7344\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5566 - accuracy: 0.7431 - val_loss: 0.5587 - val_accuracy: 0.7396\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7431 - val_loss: 0.5574 - val_accuracy: 0.7396\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5537 - accuracy: 0.7448 - val_loss: 0.5561 - val_accuracy: 0.7396\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5523 - accuracy: 0.7465 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5509 - accuracy: 0.7465 - val_loss: 0.5535 - val_accuracy: 0.7396\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.7465 - val_loss: 0.5523 - val_accuracy: 0.7396\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5482 - accuracy: 0.7465 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5469 - accuracy: 0.7500 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5456 - accuracy: 0.7517 - val_loss: 0.5487 - val_accuracy: 0.7396\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7535 - val_loss: 0.5476 - val_accuracy: 0.7396\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5431 - accuracy: 0.7552 - val_loss: 0.5464 - val_accuracy: 0.7396\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5418 - accuracy: 0.7552 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.7517 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7500 - val_loss: 0.5431 - val_accuracy: 0.7396\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5381 - accuracy: 0.7517 - val_loss: 0.5420 - val_accuracy: 0.7396\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5369 - accuracy: 0.7500 - val_loss: 0.5410 - val_accuracy: 0.7396\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.5357 - accuracy: 0.7517 - val_loss: 0.5399 - val_accuracy: 0.7396\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5345 - accuracy: 0.7535 - val_loss: 0.5389 - val_accuracy: 0.7396\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7517 - val_loss: 0.5379 - val_accuracy: 0.7396\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.7535 - val_loss: 0.5370 - val_accuracy: 0.7448\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.7535 - val_loss: 0.5360 - val_accuracy: 0.7448\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.7535 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5289 - accuracy: 0.7552 - val_loss: 0.5341 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7604 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5268 - accuracy: 0.7569 - val_loss: 0.5323 - val_accuracy: 0.7448\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5258 - accuracy: 0.7569 - val_loss: 0.5314 - val_accuracy: 0.7448\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.7569 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7587 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7587 - val_loss: 0.5288 - val_accuracy: 0.7500\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7604 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7604 - val_loss: 0.5271 - val_accuracy: 0.7500\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7604 - val_loss: 0.5263 - val_accuracy: 0.7500\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5188 - accuracy: 0.7656 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7639 - val_loss: 0.5247 - val_accuracy: 0.7500\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7674 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5160 - accuracy: 0.7674 - val_loss: 0.5231 - val_accuracy: 0.7552\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7691 - val_loss: 0.5224 - val_accuracy: 0.7552\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5142 - accuracy: 0.7691 - val_loss: 0.5216 - val_accuracy: 0.7552\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7552\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7674 - val_loss: 0.5202 - val_accuracy: 0.7552\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.7674 - val_loss: 0.5195 - val_accuracy: 0.7604\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.7674 - val_loss: 0.5188 - val_accuracy: 0.7604\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7674 - val_loss: 0.5181 - val_accuracy: 0.7604\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7691 - val_loss: 0.5175 - val_accuracy: 0.7604\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5082 - accuracy: 0.7708 - val_loss: 0.5168 - val_accuracy: 0.7604\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7708 - val_loss: 0.5162 - val_accuracy: 0.7604\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5066 - accuracy: 0.7708 - val_loss: 0.5155 - val_accuracy: 0.7604\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5058 - accuracy: 0.7691 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5050 - accuracy: 0.7726 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5043 - accuracy: 0.7726 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5036 - accuracy: 0.7726 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5028 - accuracy: 0.7726 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.7726 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5013 - accuracy: 0.7726 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5006 - accuracy: 0.7726 - val_loss: 0.5109 - val_accuracy: 0.7604\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4999 - accuracy: 0.7726 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4993 - accuracy: 0.7691 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4986 - accuracy: 0.7656 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7639 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7656 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7656 - val_loss: 0.5078 - val_accuracy: 0.7604\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.7656 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7656 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7656 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7656 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.7656 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7656 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4923 - accuracy: 0.7656 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4918 - accuracy: 0.7656 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7656 - val_loss: 0.5038 - val_accuracy: 0.7552\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7656 - val_loss: 0.5034 - val_accuracy: 0.7552\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7656 - val_loss: 0.5031 - val_accuracy: 0.7552\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4896 - accuracy: 0.7674 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4890 - accuracy: 0.7674 - val_loss: 0.5023 - val_accuracy: 0.7552\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.7674 - val_loss: 0.5020 - val_accuracy: 0.7552\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7691 - val_loss: 0.5016 - val_accuracy: 0.7552\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4875 - accuracy: 0.7708 - val_loss: 0.5013 - val_accuracy: 0.7552\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7691 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7691 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7691 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7691 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7691 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7708 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4836 - accuracy: 0.7726 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4831 - accuracy: 0.7726 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4827 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7656\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7708 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.7726 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7726 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.7691 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7552\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7656 - val_loss: 0.4964 - val_accuracy: 0.7552\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7656 - val_loss: 0.4962 - val_accuracy: 0.7552\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7656 - val_loss: 0.4959 - val_accuracy: 0.7552\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4786 - accuracy: 0.7691 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4782 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4778 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7604\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7708 - val_loss: 0.4948 - val_accuracy: 0.7604\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7691 - val_loss: 0.4946 - val_accuracy: 0.7604\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7604\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7691 - val_loss: 0.4942 - val_accuracy: 0.7604\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7708 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7708 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.7708 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7708 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7726 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7726 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7726 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.7708 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7708 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7708 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7708 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7708 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4695 - accuracy: 0.7708 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7708 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7726 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7708 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7726 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7726 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7726 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7656\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4657 - accuracy: 0.7743 - val_loss: 0.4893 - val_accuracy: 0.7656\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7656\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7656\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7760 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4887 - val_accuracy: 0.7708\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7708\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.7708\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.4885 - val_accuracy: 0.7708\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7708\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7708\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7760 - val_loss: 0.4883 - val_accuracy: 0.7708\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7708\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7708\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5398 - accuracy: 0.71 - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7656\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48186493],\n",
       "       [0.72164553],\n",
       "       [0.24366859],\n",
       "       [0.19178766],\n",
       "       [0.1897983 ],\n",
       "       [0.53701806],\n",
       "       [0.06910223],\n",
       "       [0.28691635],\n",
       "       [0.8713947 ],\n",
       "       [0.21927002]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.766\n",
      "roc-auc is 0.827\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fead4646730>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7656\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7656\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7760 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7760 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7778 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7778 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7778 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7778 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7778 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7778 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7778 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.4864 - val_accuracy: 0.7656\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7760 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7760 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.4863 - val_accuracy: 0.7656\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7760 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7760 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7760 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7760 - val_loss: 0.4862 - val_accuracy: 0.7656\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7760 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7760 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7778 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7778 - val_loss: 0.4861 - val_accuracy: 0.7656\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7778 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7778 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7778 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7778 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7778 - val_loss: 0.4861 - val_accuracy: 0.7604\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7760 - val_loss: 0.4860 - val_accuracy: 0.7604\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7760 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7760 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7760 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7778 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7778 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7778 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7795 - val_loss: 0.4860 - val_accuracy: 0.7552\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7778 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7778 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7778 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7778 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.7778 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4507 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4507 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7795 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7812 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7847 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7552\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7830 - val_loss: 0.4859 - val_accuracy: 0.7500\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4860 - val_accuracy: 0.7500\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7500\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7500\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7830 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7830 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7830 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7812 - val_loss: 0.4862 - val_accuracy: 0.7552\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7812 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.7830 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7830 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7830 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7830 - val_loss: 0.4863 - val_accuracy: 0.7552\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7830 - val_loss: 0.4864 - val_accuracy: 0.7552\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7552\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7847 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7552\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7812 - val_loss: 0.4866 - val_accuracy: 0.7604\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7812 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7604\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7847 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7865 - val_loss: 0.4865 - val_accuracy: 0.7656\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7882 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7882 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4404 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7882 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7865 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7882 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4866 - val_accuracy: 0.7656\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7899 - val_loss: 0.4867 - val_accuracy: 0.7656\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7899 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7882 - val_loss: 0.4868 - val_accuracy: 0.7656\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7882 - val_loss: 0.4869 - val_accuracy: 0.7656\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.4870 - val_accuracy: 0.7656\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7882 - val_loss: 0.4871 - val_accuracy: 0.7656\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7865 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7882 - val_loss: 0.4872 - val_accuracy: 0.7656\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4356 - accuracy: 0.7882 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7656\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7604\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7656\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.4873 - val_accuracy: 0.7708\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4907 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 912/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7708\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7795 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7830 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7847 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7830 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7830 - val_loss: 0.4872 - val_accuracy: 0.7760\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7847 - val_loss: 0.4872 - val_accuracy: 0.7760\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7847 - val_loss: 0.4872 - val_accuracy: 0.7760\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fead484c760>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Aproximademente 400 epocas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Now it's your turn.  Do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 103\n",
      "Trainable params: 103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, input_dim=8, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "learning_rate = .003\n",
    "n_epochs = 1500\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 11ms/step - loss: 0.6799 - accuracy: 0.5191 - val_loss: 0.6834 - val_accuracy: 0.5260\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6776 - accuracy: 0.5642 - val_loss: 0.6810 - val_accuracy: 0.5625\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.6128 - val_loss: 0.6787 - val_accuracy: 0.5885\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6732 - accuracy: 0.6406 - val_loss: 0.6764 - val_accuracy: 0.6094\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.6858 - val_loss: 0.6741 - val_accuracy: 0.6458\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.7049 - val_loss: 0.6718 - val_accuracy: 0.6458\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.7066 - val_loss: 0.6696 - val_accuracy: 0.6562\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.7188 - val_loss: 0.6674 - val_accuracy: 0.6615\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.7205 - val_loss: 0.6652 - val_accuracy: 0.6771\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.7274 - val_loss: 0.6631 - val_accuracy: 0.6823\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.7361 - val_loss: 0.6610 - val_accuracy: 0.6875\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6566 - accuracy: 0.7326 - val_loss: 0.6589 - val_accuracy: 0.6927\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6546 - accuracy: 0.7396 - val_loss: 0.6568 - val_accuracy: 0.6979\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.7396 - val_loss: 0.6547 - val_accuracy: 0.6979\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.7483 - val_loss: 0.6527 - val_accuracy: 0.7031\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6488 - accuracy: 0.7465 - val_loss: 0.6507 - val_accuracy: 0.7083\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.7483 - val_loss: 0.6488 - val_accuracy: 0.7188\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.7552 - val_loss: 0.6469 - val_accuracy: 0.7135\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.7587 - val_loss: 0.6450 - val_accuracy: 0.7135\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.7639 - val_loss: 0.6431 - val_accuracy: 0.7240\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6397 - accuracy: 0.7622 - val_loss: 0.6412 - val_accuracy: 0.7240\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.7552 - val_loss: 0.6394 - val_accuracy: 0.7344\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.7569 - val_loss: 0.6376 - val_accuracy: 0.7292\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.7569 - val_loss: 0.6358 - val_accuracy: 0.7292\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.7569 - val_loss: 0.6340 - val_accuracy: 0.7240\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.7604 - val_loss: 0.6323 - val_accuracy: 0.7188\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6294 - accuracy: 0.7569 - val_loss: 0.6306 - val_accuracy: 0.7240\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6277 - accuracy: 0.7622 - val_loss: 0.6289 - val_accuracy: 0.7292\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6261 - accuracy: 0.7569 - val_loss: 0.6272 - val_accuracy: 0.7292\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.7587 - val_loss: 0.6255 - val_accuracy: 0.7292\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6229 - accuracy: 0.7587 - val_loss: 0.6239 - val_accuracy: 0.7344\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.7552 - val_loss: 0.6222 - val_accuracy: 0.7344\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6197 - accuracy: 0.7569 - val_loss: 0.6206 - val_accuracy: 0.7396\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.7569 - val_loss: 0.6189 - val_accuracy: 0.7396\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.7569 - val_loss: 0.6173 - val_accuracy: 0.7396\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.7587 - val_loss: 0.6157 - val_accuracy: 0.7500\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6135 - accuracy: 0.7587 - val_loss: 0.6141 - val_accuracy: 0.7448\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.7587 - val_loss: 0.6126 - val_accuracy: 0.7448\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7587 - val_loss: 0.6111 - val_accuracy: 0.7448\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.7587 - val_loss: 0.6096 - val_accuracy: 0.7448\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.7622 - val_loss: 0.6081 - val_accuracy: 0.7448\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.7622 - val_loss: 0.6066 - val_accuracy: 0.7448\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.7622 - val_loss: 0.6052 - val_accuracy: 0.7396\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.7604 - val_loss: 0.6038 - val_accuracy: 0.7396\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6018 - accuracy: 0.7622 - val_loss: 0.6024 - val_accuracy: 0.7396\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.7622 - val_loss: 0.6010 - val_accuracy: 0.7396\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.7622 - val_loss: 0.5997 - val_accuracy: 0.7448\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5977 - accuracy: 0.7639 - val_loss: 0.5984 - val_accuracy: 0.7448\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5964 - accuracy: 0.7639 - val_loss: 0.5970 - val_accuracy: 0.7500\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.7639 - val_loss: 0.5957 - val_accuracy: 0.7552\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.7622 - val_loss: 0.5944 - val_accuracy: 0.7552\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7639 - val_loss: 0.5932 - val_accuracy: 0.7552\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7604 - val_loss: 0.5919 - val_accuracy: 0.7604\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5899 - accuracy: 0.7622 - val_loss: 0.5906 - val_accuracy: 0.7604\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7622 - val_loss: 0.5893 - val_accuracy: 0.7604\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.7604 - val_loss: 0.5881 - val_accuracy: 0.7604\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5862 - accuracy: 0.7622 - val_loss: 0.5868 - val_accuracy: 0.7604\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5849 - accuracy: 0.7639 - val_loss: 0.5856 - val_accuracy: 0.7656\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5837 - accuracy: 0.7604 - val_loss: 0.5844 - val_accuracy: 0.7656\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.7604 - val_loss: 0.5832 - val_accuracy: 0.7708\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.7622 - val_loss: 0.5820 - val_accuracy: 0.7708\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5802 - accuracy: 0.7639 - val_loss: 0.5809 - val_accuracy: 0.7708\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5790 - accuracy: 0.7639 - val_loss: 0.5797 - val_accuracy: 0.7708\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.7639 - val_loss: 0.5786 - val_accuracy: 0.7708\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.7639 - val_loss: 0.5775 - val_accuracy: 0.7760\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5756 - accuracy: 0.7639 - val_loss: 0.5764 - val_accuracy: 0.7760\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7639 - val_loss: 0.5753 - val_accuracy: 0.7760\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.7639 - val_loss: 0.5743 - val_accuracy: 0.7760\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.7639 - val_loss: 0.5732 - val_accuracy: 0.7760\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.7639 - val_loss: 0.5722 - val_accuracy: 0.7760\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7639 - val_loss: 0.5711 - val_accuracy: 0.7760\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7639 - val_loss: 0.5701 - val_accuracy: 0.7760\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.7639 - val_loss: 0.5691 - val_accuracy: 0.7760\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7639 - val_loss: 0.5682 - val_accuracy: 0.7760\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7639 - val_loss: 0.5672 - val_accuracy: 0.7708\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7639 - val_loss: 0.5663 - val_accuracy: 0.7708\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5638 - accuracy: 0.7639 - val_loss: 0.5654 - val_accuracy: 0.7708\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5629 - accuracy: 0.7639 - val_loss: 0.5644 - val_accuracy: 0.7708\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7656 - val_loss: 0.5635 - val_accuracy: 0.7708\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7674 - val_loss: 0.5626 - val_accuracy: 0.7708\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7656 - val_loss: 0.5617 - val_accuracy: 0.7708\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7656 - val_loss: 0.5608 - val_accuracy: 0.7708\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7656 - val_loss: 0.5600 - val_accuracy: 0.7708\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7656 - val_loss: 0.5591 - val_accuracy: 0.7708\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7674 - val_loss: 0.5582 - val_accuracy: 0.7708\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7656 - val_loss: 0.5574 - val_accuracy: 0.7708\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7639 - val_loss: 0.5565 - val_accuracy: 0.7708\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5530 - accuracy: 0.7674 - val_loss: 0.5557 - val_accuracy: 0.7812\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.7656 - val_loss: 0.5549 - val_accuracy: 0.7812\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7674 - val_loss: 0.5541 - val_accuracy: 0.7812\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7674 - val_loss: 0.5533 - val_accuracy: 0.7812\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7656 - val_loss: 0.5525 - val_accuracy: 0.7812\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7639 - val_loss: 0.5517 - val_accuracy: 0.7812\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7656 - val_loss: 0.5509 - val_accuracy: 0.7812\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7656 - val_loss: 0.5501 - val_accuracy: 0.7812\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7691 - val_loss: 0.5493 - val_accuracy: 0.7812\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5447 - accuracy: 0.7691 - val_loss: 0.5486 - val_accuracy: 0.7812\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7708 - val_loss: 0.5479 - val_accuracy: 0.7812\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7691 - val_loss: 0.5472 - val_accuracy: 0.7812\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5422 - accuracy: 0.7708 - val_loss: 0.5465 - val_accuracy: 0.7812\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7691 - val_loss: 0.5458 - val_accuracy: 0.7812\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7674 - val_loss: 0.5451 - val_accuracy: 0.7812\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5398 - accuracy: 0.7691 - val_loss: 0.5445 - val_accuracy: 0.7812\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5390 - accuracy: 0.7726 - val_loss: 0.5438 - val_accuracy: 0.7812\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5383 - accuracy: 0.7674 - val_loss: 0.5432 - val_accuracy: 0.7812\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5375 - accuracy: 0.7743 - val_loss: 0.5425 - val_accuracy: 0.7812\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7726 - val_loss: 0.5419 - val_accuracy: 0.7812\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5360 - accuracy: 0.7691 - val_loss: 0.5413 - val_accuracy: 0.7812\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.7778 - val_loss: 0.5407 - val_accuracy: 0.7812\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.7726 - val_loss: 0.5401 - val_accuracy: 0.7812\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7743 - val_loss: 0.5395 - val_accuracy: 0.7812\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7778 - val_loss: 0.5390 - val_accuracy: 0.7812\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7778 - val_loss: 0.5384 - val_accuracy: 0.7812\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7778 - val_loss: 0.5378 - val_accuracy: 0.7812\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7778 - val_loss: 0.5373 - val_accuracy: 0.7812\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5304 - accuracy: 0.7760 - val_loss: 0.5368 - val_accuracy: 0.7812\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7778 - val_loss: 0.5362 - val_accuracy: 0.7812\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7760 - val_loss: 0.5357 - val_accuracy: 0.7812\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7760 - val_loss: 0.5352 - val_accuracy: 0.7812\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7778 - val_loss: 0.5347 - val_accuracy: 0.7812\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7760 - val_loss: 0.5342 - val_accuracy: 0.7812\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.7778 - val_loss: 0.5337 - val_accuracy: 0.7812\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7778 - val_loss: 0.5332 - val_accuracy: 0.7812\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7778 - val_loss: 0.5328 - val_accuracy: 0.7812\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5249 - accuracy: 0.7778 - val_loss: 0.5323 - val_accuracy: 0.7812\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5243 - accuracy: 0.7760 - val_loss: 0.5319 - val_accuracy: 0.7812\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5237 - accuracy: 0.7795 - val_loss: 0.5314 - val_accuracy: 0.7812\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7778 - val_loss: 0.5310 - val_accuracy: 0.7812\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7760 - val_loss: 0.5306 - val_accuracy: 0.7812\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7760 - val_loss: 0.5302 - val_accuracy: 0.7812\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7760 - val_loss: 0.5298 - val_accuracy: 0.7812\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.7760 - val_loss: 0.5294 - val_accuracy: 0.7812\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7778 - val_loss: 0.5290 - val_accuracy: 0.7812\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7760 - val_loss: 0.5287 - val_accuracy: 0.7812\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7778 - val_loss: 0.5283 - val_accuracy: 0.7812\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7760 - val_loss: 0.5280 - val_accuracy: 0.7812\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5184 - accuracy: 0.7760 - val_loss: 0.5276 - val_accuracy: 0.7812\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7778 - val_loss: 0.5273 - val_accuracy: 0.7812\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7778 - val_loss: 0.5270 - val_accuracy: 0.7812\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7760 - val_loss: 0.5267 - val_accuracy: 0.7812\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7778 - val_loss: 0.5263 - val_accuracy: 0.7812\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7778 - val_loss: 0.5260 - val_accuracy: 0.7812\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5155 - accuracy: 0.7778 - val_loss: 0.5257 - val_accuracy: 0.7812\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.7778 - val_loss: 0.5254 - val_accuracy: 0.7812\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7778 - val_loss: 0.5251 - val_accuracy: 0.7812\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7778 - val_loss: 0.5249 - val_accuracy: 0.7812\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7778 - val_loss: 0.5246 - val_accuracy: 0.7812\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7760 - val_loss: 0.5243 - val_accuracy: 0.7812\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5127 - accuracy: 0.7830 - val_loss: 0.5240 - val_accuracy: 0.7812\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7812 - val_loss: 0.5238 - val_accuracy: 0.7760\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7812 - val_loss: 0.5235 - val_accuracy: 0.7760\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7830 - val_loss: 0.5233 - val_accuracy: 0.7760\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7812 - val_loss: 0.5230 - val_accuracy: 0.7760\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7830 - val_loss: 0.5228 - val_accuracy: 0.7760\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7830 - val_loss: 0.5225 - val_accuracy: 0.7760\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7830 - val_loss: 0.5223 - val_accuracy: 0.7760\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7830 - val_loss: 0.5221 - val_accuracy: 0.7760\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7795 - val_loss: 0.5218 - val_accuracy: 0.7760\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7830 - val_loss: 0.5216 - val_accuracy: 0.7760\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7812 - val_loss: 0.5214 - val_accuracy: 0.7760\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.7812 - val_loss: 0.5212 - val_accuracy: 0.7760\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7812 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7812 - val_loss: 0.5208 - val_accuracy: 0.7760\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7812 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7812 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7812 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7812 - val_loss: 0.5201 - val_accuracy: 0.7760\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7812 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7812 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7830 - val_loss: 0.5195 - val_accuracy: 0.7760\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7830 - val_loss: 0.5194 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7830 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7812 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7812 - val_loss: 0.5189 - val_accuracy: 0.7760\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7812 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7812 - val_loss: 0.5186 - val_accuracy: 0.7760\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7812 - val_loss: 0.5184 - val_accuracy: 0.7760\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7812 - val_loss: 0.5183 - val_accuracy: 0.7760\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7812 - val_loss: 0.5181 - val_accuracy: 0.7760\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7812 - val_loss: 0.5180 - val_accuracy: 0.7760\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7812 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7812 - val_loss: 0.5177 - val_accuracy: 0.7760\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7812 - val_loss: 0.5176 - val_accuracy: 0.7760\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7812 - val_loss: 0.5174 - val_accuracy: 0.7760\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7812 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7830 - val_loss: 0.5172 - val_accuracy: 0.7760\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7830 - val_loss: 0.5171 - val_accuracy: 0.7760\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7847 - val_loss: 0.5169 - val_accuracy: 0.7760\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7847 - val_loss: 0.5168 - val_accuracy: 0.7760\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7865 - val_loss: 0.5167 - val_accuracy: 0.7760\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7865 - val_loss: 0.5166 - val_accuracy: 0.7760\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7760\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7760\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4978 - accuracy: 0.7865 - val_loss: 0.5163 - val_accuracy: 0.7760\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.7865 - val_loss: 0.5161 - val_accuracy: 0.7760\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7865 - val_loss: 0.5160 - val_accuracy: 0.7760\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7865 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7882 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7865 - val_loss: 0.5157 - val_accuracy: 0.7760\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7882 - val_loss: 0.5156 - val_accuracy: 0.7760\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4960 - accuracy: 0.7882 - val_loss: 0.5154 - val_accuracy: 0.7760\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7865 - val_loss: 0.5153 - val_accuracy: 0.7760\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7882 - val_loss: 0.5152 - val_accuracy: 0.7760\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7882 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7865 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7865 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7865 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7865 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7865 - val_loss: 0.5146 - val_accuracy: 0.7708\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7708\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7865 - val_loss: 0.5143 - val_accuracy: 0.7708\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7865 - val_loss: 0.5142 - val_accuracy: 0.7708\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7865 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7865 - val_loss: 0.5140 - val_accuracy: 0.7708\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7865 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7882 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7865 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7882 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7882 - val_loss: 0.5136 - val_accuracy: 0.7708\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7882 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7882 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7882 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.7882 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7882 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7882 - val_loss: 0.5132 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7882 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7882 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7882 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7865 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7882 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7882 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7882 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7865 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7865 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7847 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7865 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7847 - val_loss: 0.5125 - val_accuracy: 0.7760\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7865 - val_loss: 0.5125 - val_accuracy: 0.7760\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7760\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7760\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7865 - val_loss: 0.5124 - val_accuracy: 0.7760\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7760\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7865 - val_loss: 0.5123 - val_accuracy: 0.7760\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7882 - val_loss: 0.5122 - val_accuracy: 0.7760\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7760\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7865 - val_loss: 0.5122 - val_accuracy: 0.7760\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7882 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7865 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7760\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7760\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7882 - val_loss: 0.5120 - val_accuracy: 0.7760\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4843 - accuracy: 0.7865 - val_loss: 0.5119 - val_accuracy: 0.7760\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7865 - val_loss: 0.5119 - val_accuracy: 0.7812\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7882 - val_loss: 0.5119 - val_accuracy: 0.7812\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7865 - val_loss: 0.5118 - val_accuracy: 0.7812\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7865 - val_loss: 0.5118 - val_accuracy: 0.7812\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7865 - val_loss: 0.5118 - val_accuracy: 0.7812\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7865 - val_loss: 0.5117 - val_accuracy: 0.7812\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7865 - val_loss: 0.5117 - val_accuracy: 0.7812\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7865 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7865 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7865 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7882 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7812\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7812\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7812\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7812\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7882 - val_loss: 0.5113 - val_accuracy: 0.7812\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7865 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7882 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7865 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7865 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7760\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7760\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7847 - val_loss: 0.5110 - val_accuracy: 0.7760\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7760\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7760\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7760\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7847 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7847 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7847 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7847 - val_loss: 0.5106 - val_accuracy: 0.7604\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7830 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7865 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7882 - val_loss: 0.5105 - val_accuracy: 0.7604\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7847 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7882 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7865 - val_loss: 0.5104 - val_accuracy: 0.7604\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7882 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7865 - val_loss: 0.5103 - val_accuracy: 0.7604\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7847 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7882 - val_loss: 0.5102 - val_accuracy: 0.7604\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7847 - val_loss: 0.5101 - val_accuracy: 0.7604\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7865 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7847 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7847 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7847 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7847 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7847 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7847 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7847 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7847 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7847 - val_loss: 0.5098 - val_accuracy: 0.7604\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7847 - val_loss: 0.5098 - val_accuracy: 0.7604\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7847 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7847 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7847 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7847 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7847 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7847 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7847 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7847 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7847 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7847 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7847 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7847 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7847 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7847 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7847 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7865 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7847 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7847 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7847 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7865 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7847 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7865 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7882 - val_loss: 0.5087 - val_accuracy: 0.7604\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7865 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7865 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7847 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7847 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7847 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7847 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7847 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7847 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7847 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7830 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7882 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7917 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7865 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7899 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7865 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7865 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7865 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7865 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7865 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7882 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7882 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7882 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7882 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7882 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7865 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7865 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7882 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7865 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7865 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.7865 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7865 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7882 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7865 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7865 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7865 - val_loss: 0.5075 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7882 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7865 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7865 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7865 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7865 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7865 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7865 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7865 - val_loss: 0.5077 - val_accuracy: 0.7500\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7899 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7882 - val_loss: 0.5078 - val_accuracy: 0.7500\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7865 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7865 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7899 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7899 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7899 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7396\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7899 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4474 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7899 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7899 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7899 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7899 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7882 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7865 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7865 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7882 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7899 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7917 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7934 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7934 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7934 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5089 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7604\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7934 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7951 - val_loss: 0.5091 - val_accuracy: 0.7604\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7951 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7969 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7951 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7951 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7951 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7951 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7951 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7951 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7951 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7969 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2824 - accuracy: 0.87 - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7951 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7951 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7951 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7951 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7951 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1026/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7986 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7986 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7986 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7969 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7969 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7986 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7986 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7969 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7986 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7986 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7986 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7986 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.5110 - val_accuracy: 0.7500\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5111 - val_accuracy: 0.7500\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5112 - val_accuracy: 0.7500\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1082/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7500\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1138/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4248 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1194/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8003 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8021 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8003 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8021 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8021 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8038 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8021 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8021 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8021 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7500\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8021 - val_loss: 0.5116 - val_accuracy: 0.7500\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8021 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8038 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1250/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8003 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8003 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8038 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8021 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8038 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8021 - val_loss: 0.5119 - val_accuracy: 0.7604\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1306/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8038 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7604\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8003 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8021 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8003 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8021 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8021 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8021 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8003 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8038 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8003 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8056 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8038 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8021 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8003 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8038 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4201 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8056 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 1362/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8038 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4199 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8056 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8038 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8038 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8056 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8073 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8038 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8056 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.8073 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8073 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8073 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8056 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8073 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8073 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8073 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8073 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8073 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8038 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8073 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8073 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8056 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 1418/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8073 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8073 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8038 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8073 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8038 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8038 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8056 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4187 - accuracy: 0.8038 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8038 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8038 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8038 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8056 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8038 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8056 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4183 - accuracy: 0.8038 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8038 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1474/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8056 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8056 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8073 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8056 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8056 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8038 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8056 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8056 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8056 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.8038 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8038 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8056 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8073 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8056 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8056 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8056 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8056 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8073 - val_loss: 0.5136 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fead4c4eb50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist.history[\"loss\"])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(range(n), run_hist.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
